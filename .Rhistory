local({pkg <- select.list(sort(.packages(all.available = TRUE)),graphics=TRUE)
if(nchar(pkg)) library(pkg, character.only=TRUE)})
.libpaths()
.libPaths()
q()
find.packages("devtool")
find.package("devtool")
find.package("devtools")
q()
pollutantmean("specdata", "sulfate", 1:10)
install.packages("swirl")
packageVersion("swirl")
library(swirl)
install_from_swirl("R Programming")
install_from_swirl("R Programming")
source"http://bioconductor.org/biocLite.R"
source ("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library(httr)
require(httpuv)
require(jsonlite)
install.packages("httpuv")
library(httr)
require(httpuv)
require(jsonlite)
oauth_endpoints("github")
myapp <- oauth_app("Coursera1", "3fc532336d1f507d18f3", secret="443af81ebcaa1575f661c6df3345b2df57766797")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
use_cache <- function(cache = getOption("httr_oauth_cache")) {
if (length(cache) != 1) {
stop("cache should be length 1 vector", call. = FALSE)
}
if (!is.logical(cache) && !is.character(cache)) {
stop("Cache must either be logical or string (file path)")
}
# If it's a character, then it's a file path, so use it
if (is.character(cache)) return(cache)
# If missing, see if it's ok to use one, and cache the results of
# that check in a global option.
if (is.na(cache)) {
cache <- can_use_cache()
options("httr_oauth_cache" = cache)
}
if (cache) ".httr-oauth" else NULL
}
can_use_cache <- function(path = ".httr-oauth") {
file.exists(path) || (should_cache(path) && create_cache(path))
}
should_cache <- function(path = ".httr-oauth") {
if (!interactive()) return(FALSE)
cat("Use a local file ('", path, "'), to cache OAuth access credentials ",
"between R sessions?\n", sep = "")
utils::menu(c("Yes", "No")) == 1
}
create_cache <- function(path = ".httr-oauth") {
file.create(path, showWarnings = FALSE)
if (!file.exists(path)) {
stop("Failed to create local cache ('", path, "')", call. = FALSE)
}
# Protect cache as much as possible
Sys.chmod(path, "0600")
if (file.exists("DESCRIPTION")) {
add_line(".Rbuildignore", paste0("^", gsub("\\.", "\\\\.", path), "$"))
}
add_line(".gitignore", path)
TRUE
}
add_line <- function(path, line, quiet = FALSE) {
if (file.exists(path)) {
lines <- readLines(path, warn = FALSE)
lines <- lines[lines != ""]
} else {
lines <- character()
}
if (line %in% lines) return(TRUE)
if (!quiet) message("Adding ", line, " to ", path)
lines <- c(lines, line)
writeLines(lines, path)
TRUE
}
cache_token <- function(token, cache_path) {
if (is.null(cache_path)) return()
tokens <- load_cache(cache_path)
tokens[[token$hash()]] <- token
saveRDS(tokens, cache_path)
}
fetch_cached_token <- function(hash, cache_path) {
if (is.null(cache_path)) return()
load_cache(cache_path)[[hash]]
}
remove_cached_token <- function(token) {
if (is.null(token$cache_path)) return()
tokens <- load_cache(token$cache_path)
tokens[[token$hash()]] <- NULL
saveRDS(tokens, token$cache_path)
}
load_cache <- function(cache_path) {
if (!file.exists(cache_path)) {
list()
} else {
readRDS(cache_path)
}
}
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
install.packages(c("dplyr", "jsonlite", "swirl", "withr", "XLConnect", "XLConnectJars", "xml2"))
library(swirl)
swirl()
install_from_swirl("Getting and Cleaning Data")
swril()
swirl()
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id,package, country)
5:20
select(r_arch:country)
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time
)
select(cran, -(x:size))
select(cran, -(X:size))
-5:20
-(5:20)
select(cran, -(X:size))
filter(cran, package=="swirl" )
filter(cran, r_version == "3.1.1", country == "ind")
View(cran)
filter(cran, r_version == "3.1.1", country == "IN")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version <= "3.0.1", country == "IN")
filter(cran, r_version <= "3.0.2", country == "IN")
(cran, country == "US" | country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500 & r_os == "linux-gnu")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA,10))
!is.na(c(3, 5, NA,10))
filter(cran, r_version !is.na())
filter(cran, r_version == !is.na())
filter(cran, is.na(c(3, 5, NA, 10)))
filter(cran, is.na(c(3, 5, NA)))
filter(cran, is.na(c(5, NA)))
filter(cran, !is.na(c(3, 5, NA)))
!is.na(c(3, 5, NA,10))
filter(cran, !is.na(r_version))
View(cran2)
select(cran, size:ip_id)
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(ip_id, package, size)
cran3 <- select(cran, ip_id, package, size)
head(cran3)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size+1000)
summarize(cran, avg_size = mean(size))
(cran, avg_bytes = mean(size))
summarise(cran, avg_bytes = mean(size))
summarize(cran, avg_bytes = mean(size))
library(dplyr)
?tbl_df
cran <- tbl_df(mydf)
mydf
rm("mydf")
cran
?group_by
by_package <- group_by(cran, package)
by_package
summarise(by_package, mean(size))
reset()
swirl()
?n
?n_distinct
pack_sum <- summarize(by_package,
count = n(),
unique = n_distinct(ip_id),
countries = n_distinct(country),
avg_bytes = mean(size))
submit()
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
filter(pack_sum, count>679)
filter(pack_sum, count>679)
filter(pack_sum, count > 679)
top_counts <- filter(pack_sum, count > 679)
top_counts
View(pack_sum)
View(top_counts)
top_counts_sorted <-arrange(count)
top_counts_sorted <- arrange(top_counts, count)
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique()))
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
cran %>%
select(ip_id, country, package, size) %>%
print
cran %>%
select(ip_id, country, package, size) %>%
print
exit()
info()
main()
bye()
swirl()
cran %>%
select() %>%
print
skip()
cran %>%
select(ip_id, country, package, size) %>%
mutate(size_mb = size / 2^20)
print
?mutate
skip()
cran %>%
select(ip_id, country, package, size) %>%
mutate(size_mb = size / 2^20) %>%
filter(size_mb <= 0.5)
skip()
cran %>%
select(ip_id, country, package, size) %>%
mutate(size_mb = size / 2^20) %>%
filter(size_mb <= 0.5) %>%
arrange(desc(size_mb))
skip()
swirl()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
res <- gather(students2, sex_class, count)
res <- gather(students2, sex_class, count, -grade)
res
?seperate
?separate
separate(res, sex_class, c("sex", "class"))
View(students2)
View(students)
View(students2)
students2 %>%
gather(sex_class, count, -grade ) %>%
separate(sex_class, c("sex", "class")) %>%
print
info()
nxt()
submit()
submit()
submit()
students3
?gather
submit()
submit()
?spread
submit()
submit()
skip()
extract_numeric("class5")
skip()
students4
skip()
skip()
submit()
passed
failed
skip()
skip()
skip()
sat
skip()
skip()
swirl()
View(by_package)
View(by_package)
swirl()
library(swirl)
swirl()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package =  lubridate)
this_day <- today()
this_day
day(this_day)
wday(this_day)
wday(this_day, label = T)
wday(this_day, label = TRUE)
this_moment <- now()
this_moment
hour(this_moment)
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 MAy 17")
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("//192012")
ymd("1920/1/2")
dt1
ymd_hms(dt1)
?hms
hms("03:22:14")
dt2
ymd(dt2)
this_moment
update(this_moment hours = 8, minute = 34, second = 55)
update(this_moment, hours = 8, minute = 34, second = 55)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
now()
this_moment <- now()
update(this_moment, hours = 21, minutes = 13, seconds = 7)
this_moment
?now
nyc <- now(tzone = "America/New_York")
nyc
nyc + days(2)
depart <- nyc +days(2)
depart
update(depart, hours = 17, minutes = 34)
skip()
depart
arrive <- depart + hours(15) + minutes(50)
?with_tz
with_tz(arrive, tzone = "Asia/Hong_Kong")
with_tz(arrive, "Asia/Hong_Kong")
skip()
arrive
last_time <- mdy("June 17, 2008", tz = "Singapore")
last_time
?interval
how_long <- interval(last_time, arrive)
how_long
as.period(how_long)
stopwatch()
setwd("~/Coursera/Data Science/Getting&Cleaning_Data/Project")
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileUrl,destfile="./data/Dataset.zip")
unzip(zipfile="./data/Dataset.zip", exdir="./data")
path_rf <- file.path("./data" , "UCI HAR Dataset")
files<-list.files(path_rf, recursive=TRUE)
files
dataActivityTest  <- read.table(file.path(path_rf, "test" , "Y_test.txt" ),header = FALSE)
dataActivityTrain <- read.table(file.path(path_rf, "train", "Y_train.txt"),header = FALSE)
dataSubjectTrain <- read.table(file.path(path_rf, "train", "subject_train.txt"),header = FALSE)
dataSubjectTest  <- read.table(file.path(path_rf, "test" , "subject_test.txt"),header = FALSE)
dataFeaturesTest  <- read.table(file.path(path_rf, "test" , "X_test.txt" ),header = FALSE)
dataFeaturesTrain <- read.table(file.path(path_rf, "train", "X_train.txt"),header = FALSE)
str(dataActivityTest)
str(dataActivityTrain)
str(dataSubjectTrain)
str(dataSubjectTest)
str(dataFeaturesTest)
str(dataFeaturesTrain)
dataCombine <- cbind(dataSubject, dataActivity)
MasterData <- cbind(dataFeatures, dataCombine)
dataSubject <- rbind(dataSubjectTrain, dataSubjectTest)
dataActivity<- rbind(dataActivityTrain, dataActivityTest)
dataFeatures<- rbind(dataFeaturesTrain, dataFeaturesTest)
names(dataSubject)<-c("subject")
names(dataActivity)<- c("activity")
dataFeaturesNames <- read.table(file.path(path_rf, "features.txt"),head=FALSE)
names(dataFeatures)<- dataFeaturesNames$V2
dataCombine <- cbind(dataSubject, dataActivity)
MasterData <- cbind(dataFeatures, dataCombine)
NamesFeatSubdata<-dataFeaturesNames$V2[grep("mean\\(\\)|std\\(\\)", dataFeaturesNames$V2)]
str(MasterData)
selectedNames<-c(as.character(NamesFeatSubdata), "subject", "activity" )
MasterData<-subset(MasterData,select=selectedNames)
activityLabels <- read.table(file.path(path_rf, "activity_labels.txt"),header = FALSE)
head(MasterData$activity)
View(activityLabels)
MasterData$activity <- as.character(MasterData$activity)
MasterData$activity[MasterData$activity == 1] <- "WALKING"
MasterData$activity[MasterData$activity == 2] <- "WALKING_UPSTAIRS"
MasterData$activity[MasterData$activity == 3] <- "WALKING_DOWNSTAIRS"
MasterData$activity[MasterData$activity == 4] <- "SITTING"
MasterData$activity[MasterData$activity == 5] <- "STANDING"
MasterData$activity[MasterData$activity == 6] <- "LAYING"
MasterData$activity <- as.factor(MasterData$activity)
head(MasterData$activity)
names(MasterData)<-gsub("^t", "time", names(MasterData))
names(MasterData)<-gsub("^f", "frequency", names(MasterData))
names(MasterData)<-gsub("Acc", "Accelerometer", names(MasterData))
names(MasterData)<-gsub("Gyro", "Gyroscope", names(MasterData))
names(MasterData)<-gsub("Mag", "Magnitude", names(MasterData))
names(MasterData)<-gsub("BodyBody", "Body", names(MasterData))
names(MaasterData)
names(MasterData)
MasterDAta2 <- data.table(MasterData)
library(plyr);
MasterDAta2 <- data.table(MasterData)
library(data.table);
MasterDAta2 <- data.table(MasterData)
TidyData <- MasterDAta2[, lapply(.SD, mean), by = 'subject,activity']
write.table(TidyData, file = "Tidy_Data.txt", row.names = FALSE)
library(knitr)
knit2html("codebook.Rmd")
